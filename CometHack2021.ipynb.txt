{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CometHack2021.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "nKsHl6phiFck",
        "GpCC3vUyzzFH"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PJDJqI1bH_c",
        "outputId": "ea517475-efc6-4c0c-9c17-1620a7b3e3d1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxWRSGo_w_hF"
      },
      "source": [
        "# general imports\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "# deep learning libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "# image manipulation libraries\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from PIL import Image\n",
        "from skimage.feature import hog\n",
        "from skimage.color import rgb2grey\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvBV97mh1Igl"
      },
      "source": [
        "__Project Plan:__\n",
        "* Data Preprocessing\n",
        "  * process original images (put into dataframe, resize)\n",
        "  * artificially create new images (crop, rotate, flip)\n",
        "  * PCA or NMF potentially? need to look back into\n",
        "* Training\n",
        "  * split into train, test, and eval sets (evaluation for end product showcasing- very small)\n",
        "  * create Sequential keras model with arrangement of layers- figure out which ones in which order\n",
        "  * train until accuracy isn't improving- activation functions @ whatnot need to be figured out\n",
        "* Showcase\n",
        "  * create pretty images showing what we've done w/ matplotlib or seaborn (preferably on slideshow, not actually going to code itself)\n",
        "  * potentially create mock GUI in Figma? May help presentation if we have time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stxZtwjC1j1T"
      },
      "source": [
        "__PReLU vs. ReLU__\n",
        "* ReLU: if x > 0: x; else: 0\n",
        "* Parameterized ReLU: uses a negative linear function with adjustable coefficient to control the slope, reducong to ReLU with the coefficient is 0\n",
        "\n",
        "\n",
        "*from Galaxy Classifications with Deep Learning by Lukic and Bruggen*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obvBUeJ53m4J"
      },
      "source": [
        "__PCA vs. NMF__\n",
        "* NMF (Non-negative Matrix Factorization) is similar to PCA (Priciple Component Analysis) but utilizes only non-negative features of the matrices, allowing to to find the parts of a whole"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmKLJRdLEzVS"
      },
      "source": [
        "#Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eL56gZKNhAl"
      },
      "source": [
        "\"\"\"uses grabCut from OpenCV on an image to isolate the foreground\"\"\"\n",
        "def grab_cut(img):\n",
        "  # resize original image and create a mask to be altered by grabCut\n",
        "  resized_img = cv2.resize(img, (250,250))\n",
        "  mask = np.zeros((resized_img.shape[:2]),np.uint8)\n",
        "\n",
        "  # models used internally to the grabCut\n",
        "  bgdModel = np.zeros((1,65),np.float64)\n",
        "  fgdModel = np.zeros((1,65),np.float64)\n",
        "\n",
        "  rect = (50, 50, 150, 150) # bounding rectangle for foreground\n",
        "  cv2.grabCut(resized_img, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT) # 5 iterations using rectangle\n",
        "\n",
        "  # binarize background and foreground\n",
        "  mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
        "\n",
        "  # create final image by multiplying by new mask\n",
        "  final_img = resized_img*mask2[:,:,np.newaxis]\n",
        "  return final_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFpHClmT6dU_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7642be2-8bf1-4054-93d8-c466d63cd679"
      },
      "source": [
        "size = (50,50,3) # resize to what?\n",
        "\"\"\" preprocess for each image type \"\"\"\n",
        "\n",
        "def do_picture_stuff(path,label):\n",
        "  img_data_list = []\n",
        "  label_list = []\n",
        "  for filename in os.listdir(path):\n",
        "    img_path = os.path.join(path,filename)\n",
        "    image = cv2.imread(img_path)\n",
        "    print('working on', img_path)\n",
        "\n",
        "    for angle in (0,90,180,270):\n",
        "      new_img = grab_cut(image) # comment out this line to not grabcut the image\n",
        "      new_img = Image.fromarray(new_img).rotate(angle)\n",
        "      img_data_list.append(np.asarray(np.resize(new_img, size)))\n",
        "      label_list.append(label)\n",
        "  return (img_data_list,label_list)\n",
        "\n",
        "\n",
        "# for path, label in (('drive/MyDrive/CometHack2021/not_poision_ivy_pictures', [1., 0., 0.]), ('drive/MyDrive/CometHack2021/poison_ivy_pictures', [0., 1.,0.]), ('drive/MyDrive/CometHack2021/poison_oak_pictures', [0., 0.,1.])):\n",
        "\n",
        "\n",
        "poison_list, poison_labels = do_picture_stuff('drive/MyDrive/CometHack2021/poison_ivy_pictures', [0., 1.,0.])\n",
        "tmp = do_picture_stuff('drive/MyDrive/CometHack2021/poison_oak_pictures', [0., 0.,1.])\n",
        "poison_list += tmp[0]\n",
        "poison_labels += tmp[1]\n",
        "\n",
        "not_list, not_labels = do_picture_stuff('drive/MyDrive/CometHack2021/not_poision_ivy_pictures', [1., 0., 0.])\n",
        "\n",
        "false_list, false_labels = do_picture_stuff('drive/MyDrive/CometHack2021/False', [1., 0., 0.])\n",
        "\n",
        "iris_list, iris_labels = do_picture_stuff('drive/MyDrive/CometHack2021/Irises', [1., 0., 0.])\n",
        "\n",
        "\n",
        "\n",
        "plant_imgs = np.array(img_data_list)\n",
        "plant_labels = np.array(label_list)\n",
        "ls = np.array(label_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy1.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy3.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy4.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy2.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy5.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy6.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy7.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy10.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy11.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy12.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy14.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy16.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy18.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy19.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy21.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy22.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy25.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy28.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy29.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy31.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy33.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy30.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy27.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy26.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy23.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy15.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy8.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy9.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy17.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy20.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy24.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy32.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_ivy_pictures/ivy13.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak26.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak17.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak22.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak16.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak1.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/poison-oak-identify-treat.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak6.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak11.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak15.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak5.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak10.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak19.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak24.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak4.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak13.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak7.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak28.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak14.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak27.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak8.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak23.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak29.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak20.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak2.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak9.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak18.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak21.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak3.jpg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak30.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak31.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak12.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak.jpeg\n",
            "working on drive/MyDrive/CometHack2021/poison_oak_pictures/oak25.jpeg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not1.jpg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not2.jpg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not3.jpg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not4.jpg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not6.jpg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not7.jpg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not8.jpg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not10.jpg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not5.jpg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not9.jpg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not11.jpg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not29.jpeg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not32.jpeg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not25.jpeg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not12.jpeg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not20.jpeg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not21.jpeg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not23.jpeg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not.jpeg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not22.jpeg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not31.jpeg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not30.jpeg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not15.jpeg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not28.jpeg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not16.jpeg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not33.jpeg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not13.jpeg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not24.jpeg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not17.jpeg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not26.jpeg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not34.jpeg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not19.jpeg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not14.jpeg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not18.jpeg\n",
            "working on drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not27.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false6.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false31.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false32.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false3.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false16.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false27.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false29.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false25.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false8.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false14.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false10.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false28.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false7.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false24.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false9.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false15.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false12.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false23.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false17.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false21.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false19.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false13.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false4.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false2.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false11.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false22.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false20.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false26.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false18.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false30.jpeg\n",
            "working on drive/MyDrive/CometHack2021/False/false5.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris28.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris12.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris6.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris11.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris23.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris4.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris9.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris22.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris32.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris30.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris27.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris20.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris18.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris29.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris16.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris2.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris14.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris1.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris8.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris13.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris19.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris3.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris5.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris7.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris21.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris15.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris17.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris31.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris25.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris26.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris24.jpeg\n",
            "working on drive/MyDrive/CometHack2021/Irises/iris10.jpeg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds19p1U5acum"
      },
      "source": [
        "'''path = 'drive/MyDrive/CometHack2021/not_poision_ivy_pictures/not1.jpg'\n",
        "img = cv2.imread(path)\n",
        "resized_img = cv2.resize(img, (250,250))\n",
        "mask = np.zeros((resized_img.shape[:2]),np.uint8)\n",
        "\n",
        "# models used internally to the grabCut\n",
        "bgdModel = np.zeros((1,65),np.float64)\n",
        "fgdModel = np.zeros((1,65),np.float64)\n",
        "\n",
        "rect = (50, 50, 150, 150) # bounding rectangle for foreground\n",
        "cv2.grabCut(resized_img, mask, rect, bgdModel, fgdModel, 10, cv2.GC_INIT_WITH_RECT) # 5 iterations using rectangle\n",
        "\n",
        "# binarize background and foreground\n",
        "mask2 = np.where((mask==2)|(mask==0),0,1).astype('uint8')\n",
        "\n",
        "# create final image by multiplying by new mask\n",
        "final_img = resized_img*mask2[:,:,np.newaxis]\n",
        "\n",
        "plt.imshow(final_img)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyFfa1U-hRMf"
      },
      "source": [
        "def hog_it(imgs):\n",
        "  img_list = []\n",
        "  for image in imgs:\n",
        "    img_list.append(np.array(hog(image, orientations=9, pixels_per_cell=(2,2))))\n",
        "  return np.array(img_list)\n",
        "\n",
        "poison_hog = hog_it(poison_list)\n",
        "iris_hog = hog_it(iris_list)\n",
        "not_la_hog = hog_it(not_list)\n",
        "false_pg_hog = hog_it(false_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKsHl6phiFck"
      },
      "source": [
        "#Model with nots (look-alikes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELSjPhsMiI8G",
        "outputId": "41a7d02c-93df-48e1-ee49-2f22f348fa44"
      },
      "source": [
        "poison_nots = np.concatenate((poison_hog, not_la_hog))\n",
        "pn_labels = np.concatenate((poison_labels, not_labels))\n",
        "x_train, x_temp, y_train, y_temp = train_test_split(poison_nots, pn_labels, test_size=.2)\n",
        "x_test, x_eval, y_test, y_eval = train_test_split(x_temp, y_temp, test_size=.03, random_state=5)\n",
        "\n",
        "print('xtrain:\\t',len(x_train))\n",
        "print('xtest:\\t',len(x_test))\n",
        "print('xeval:\\t',len(x_eval))\n",
        "print(y_eval)\n",
        "\n",
        "len(x_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "xtrain:\t 323\n",
            "xtest:\t 78\n",
            "xeval:\t 3\n",
            "[[0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42849"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoRsoycxkh51",
        "outputId": "47cbee6e-36cf-414c-8c0c-cd87329e91f8"
      },
      "source": [
        "model = keras.models.Sequential()\n",
        "model.add(Dense(50, activation='relu', input_shape=(42849,)))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dropout(.1))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_42 (Dense)             (None, 50)                2142500   \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 3)                 153       \n",
            "=================================================================\n",
            "Total params: 2,145,203\n",
            "Trainable params: 2,145,203\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4PniZHSmkLL",
        "outputId": "b959429f-bdc4-469c-ef6e-7bdf05f8a3ac"
      },
      "source": [
        "model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(learning_rate=.001), metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=100, validation_data=(x_test, y_test))\n",
        "\n",
        "test_eval = model.evaluate(x_test, y_test, verbose=False)\n",
        "print(\"Test loss, accuracy: %s, %s\" % (test_eval[0], test_eval[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "11/11 [==============================] - 1s 40ms/step - loss: 0.6927 - accuracy: 0.3707 - val_loss: 0.6914 - val_accuracy: 0.3333\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6910 - accuracy: 0.3263 - val_loss: 0.6899 - val_accuracy: 0.3590\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6895 - accuracy: 0.3161 - val_loss: 0.6884 - val_accuracy: 0.3333\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6880 - accuracy: 0.3341 - val_loss: 0.6869 - val_accuracy: 0.3333\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6866 - accuracy: 0.3040 - val_loss: 0.6856 - val_accuracy: 0.3333\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6852 - accuracy: 0.3550 - val_loss: 0.6843 - val_accuracy: 0.3333\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6840 - accuracy: 0.3336 - val_loss: 0.6831 - val_accuracy: 0.3333\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6827 - accuracy: 0.3285 - val_loss: 0.6818 - val_accuracy: 0.3333\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6815 - accuracy: 0.3316 - val_loss: 0.6806 - val_accuracy: 0.3333\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6803 - accuracy: 0.3080 - val_loss: 0.6794 - val_accuracy: 0.3333\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6791 - accuracy: 0.3164 - val_loss: 0.6782 - val_accuracy: 0.3333\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6779 - accuracy: 0.3359 - val_loss: 0.6771 - val_accuracy: 0.3333\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.6768 - accuracy: 0.3062 - val_loss: 0.6759 - val_accuracy: 0.3333\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6757 - accuracy: 0.3136 - val_loss: 0.6748 - val_accuracy: 0.3077\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6745 - accuracy: 0.3685 - val_loss: 0.6738 - val_accuracy: 0.3077\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.6735 - accuracy: 0.3343 - val_loss: 0.6727 - val_accuracy: 0.3077\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6725 - accuracy: 0.3317 - val_loss: 0.6717 - val_accuracy: 0.3077\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6714 - accuracy: 0.3377 - val_loss: 0.6707 - val_accuracy: 0.3077\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.6704 - accuracy: 0.3486 - val_loss: 0.6697 - val_accuracy: 0.3077\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6694 - accuracy: 0.3357 - val_loss: 0.6687 - val_accuracy: 0.3077\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6684 - accuracy: 0.3491 - val_loss: 0.6678 - val_accuracy: 0.3077\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6675 - accuracy: 0.3352 - val_loss: 0.6669 - val_accuracy: 0.3077\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6665 - accuracy: 0.3848 - val_loss: 0.6660 - val_accuracy: 0.3077\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6657 - accuracy: 0.3309 - val_loss: 0.6651 - val_accuracy: 0.3077\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6649 - accuracy: 0.3205 - val_loss: 0.6643 - val_accuracy: 0.3077\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.6641 - accuracy: 0.3113 - val_loss: 0.6635 - val_accuracy: 0.3077\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6632 - accuracy: 0.3322 - val_loss: 0.6627 - val_accuracy: 0.3077\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6625 - accuracy: 0.3079 - val_loss: 0.6619 - val_accuracy: 0.3077\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6616 - accuracy: 0.3495 - val_loss: 0.6612 - val_accuracy: 0.3077\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.6610 - accuracy: 0.3219 - val_loss: 0.6605 - val_accuracy: 0.3077\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.6602 - accuracy: 0.3351 - val_loss: 0.6597 - val_accuracy: 0.3077\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6595 - accuracy: 0.3131 - val_loss: 0.6591 - val_accuracy: 0.3077\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.6587 - accuracy: 0.3384 - val_loss: 0.6584 - val_accuracy: 0.3077\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6579 - accuracy: 0.3325 - val_loss: 0.6577 - val_accuracy: 0.3077\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6574 - accuracy: 0.3387 - val_loss: 0.6571 - val_accuracy: 0.3077\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6568 - accuracy: 0.3241 - val_loss: 0.6564 - val_accuracy: 0.3077\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6562 - accuracy: 0.3116 - val_loss: 0.6558 - val_accuracy: 0.3077\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6555 - accuracy: 0.3340 - val_loss: 0.6552 - val_accuracy: 0.3077\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6550 - accuracy: 0.3462 - val_loss: 0.6546 - val_accuracy: 0.3077\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6544 - accuracy: 0.3241 - val_loss: 0.6540 - val_accuracy: 0.3077\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6538 - accuracy: 0.3477 - val_loss: 0.6535 - val_accuracy: 0.3077\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6532 - accuracy: 0.3440 - val_loss: 0.6529 - val_accuracy: 0.3077\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6528 - accuracy: 0.2738 - val_loss: 0.6524 - val_accuracy: 0.3333\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6522 - accuracy: 0.3582 - val_loss: 0.6519 - val_accuracy: 0.3333\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6517 - accuracy: 0.3373 - val_loss: 0.6514 - val_accuracy: 0.3333\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6512 - accuracy: 0.3598 - val_loss: 0.6509 - val_accuracy: 0.3333\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6508 - accuracy: 0.3020 - val_loss: 0.6504 - val_accuracy: 0.3077\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6503 - accuracy: 0.3011 - val_loss: 0.6500 - val_accuracy: 0.3333\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6499 - accuracy: 0.3416 - val_loss: 0.6496 - val_accuracy: 0.3333\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.6495 - accuracy: 0.3206 - val_loss: 0.6491 - val_accuracy: 0.3333\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6490 - accuracy: 0.3266 - val_loss: 0.6487 - val_accuracy: 0.3333\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6486 - accuracy: 0.3239 - val_loss: 0.6483 - val_accuracy: 0.3333\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6482 - accuracy: 0.3268 - val_loss: 0.6479 - val_accuracy: 0.3333\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.6478 - accuracy: 0.3530 - val_loss: 0.6476 - val_accuracy: 0.3333\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6476 - accuracy: 0.2963 - val_loss: 0.6472 - val_accuracy: 0.3333\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6472 - accuracy: 0.3104 - val_loss: 0.6469 - val_accuracy: 0.3333\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6468 - accuracy: 0.3165 - val_loss: 0.6465 - val_accuracy: 0.3333\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6465 - accuracy: 0.3267 - val_loss: 0.6462 - val_accuracy: 0.3333\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6461 - accuracy: 0.3474 - val_loss: 0.6459 - val_accuracy: 0.3333\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6458 - accuracy: 0.3385 - val_loss: 0.6455 - val_accuracy: 0.3333\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6455 - accuracy: 0.3200 - val_loss: 0.6452 - val_accuracy: 0.3333\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.6452 - accuracy: 0.3418 - val_loss: 0.6450 - val_accuracy: 0.3333\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6450 - accuracy: 0.3193 - val_loss: 0.6447 - val_accuracy: 0.3333\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6447 - accuracy: 0.3021 - val_loss: 0.6444 - val_accuracy: 0.3333\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6445 - accuracy: 0.3122 - val_loss: 0.6441 - val_accuracy: 0.3333\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6440 - accuracy: 0.3653 - val_loss: 0.6438 - val_accuracy: 0.3333\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6438 - accuracy: 0.3409 - val_loss: 0.6436 - val_accuracy: 0.3333\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6437 - accuracy: 0.3007 - val_loss: 0.6433 - val_accuracy: 0.3590\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6434 - accuracy: 0.3071 - val_loss: 0.6431 - val_accuracy: 0.3590\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6432 - accuracy: 0.3041 - val_loss: 0.6428 - val_accuracy: 0.3590\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6428 - accuracy: 0.3657 - val_loss: 0.6426 - val_accuracy: 0.3590\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.6426 - accuracy: 0.3553 - val_loss: 0.6424 - val_accuracy: 0.3590\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6425 - accuracy: 0.3413 - val_loss: 0.6422 - val_accuracy: 0.3590\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6423 - accuracy: 0.3281 - val_loss: 0.6420 - val_accuracy: 0.3590\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6421 - accuracy: 0.3382 - val_loss: 0.6418 - val_accuracy: 0.3590\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6417 - accuracy: 0.3634 - val_loss: 0.6416 - val_accuracy: 0.3590\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6417 - accuracy: 0.3321 - val_loss: 0.6414 - val_accuracy: 0.3590\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6414 - accuracy: 0.3641 - val_loss: 0.6412 - val_accuracy: 0.3590\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6413 - accuracy: 0.3439 - val_loss: 0.6410 - val_accuracy: 0.3590\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6412 - accuracy: 0.3357 - val_loss: 0.6409 - val_accuracy: 0.3590\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6410 - accuracy: 0.3331 - val_loss: 0.6407 - val_accuracy: 0.3590\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6408 - accuracy: 0.3490 - val_loss: 0.6405 - val_accuracy: 0.3590\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6405 - accuracy: 0.3559 - val_loss: 0.6404 - val_accuracy: 0.3590\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6403 - accuracy: 0.3650 - val_loss: 0.6402 - val_accuracy: 0.3590\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6406 - accuracy: 0.3251 - val_loss: 0.6401 - val_accuracy: 0.3590\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.6402 - accuracy: 0.3501 - val_loss: 0.6400 - val_accuracy: 0.3590\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6403 - accuracy: 0.3225 - val_loss: 0.6398 - val_accuracy: 0.3590\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6401 - accuracy: 0.3347 - val_loss: 0.6397 - val_accuracy: 0.3590\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6397 - accuracy: 0.3530 - val_loss: 0.6396 - val_accuracy: 0.3590\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6399 - accuracy: 0.3291 - val_loss: 0.6395 - val_accuracy: 0.3590\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - 0s 24ms/step - loss: 0.6396 - accuracy: 0.3422 - val_loss: 0.6393 - val_accuracy: 0.3590\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6394 - accuracy: 0.3534 - val_loss: 0.6392 - val_accuracy: 0.3590\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6393 - accuracy: 0.3487 - val_loss: 0.6391 - val_accuracy: 0.3590\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6395 - accuracy: 0.3209 - val_loss: 0.6390 - val_accuracy: 0.3590\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6393 - accuracy: 0.3330 - val_loss: 0.6389 - val_accuracy: 0.3590\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6390 - accuracy: 0.3453 - val_loss: 0.6388 - val_accuracy: 0.3590\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.6391 - accuracy: 0.3310 - val_loss: 0.6387 - val_accuracy: 0.3590\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6389 - accuracy: 0.3434 - val_loss: 0.6386 - val_accuracy: 0.3590\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.6389 - accuracy: 0.3361 - val_loss: 0.6385 - val_accuracy: 0.3590\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - 0s 25ms/step - loss: 0.6391 - accuracy: 0.3170 - val_loss: 0.6384 - val_accuracy: 0.3590\n",
            "Test loss, accuracy: 0.6384246945381165, 0.3589743673801422\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_p_i4Tfs0Bj",
        "outputId": "5e9acfb8-f077-4598-8cb9-6cbea9dc46d1"
      },
      "source": [
        "print(y_eval)\n",
        "model.predict(x_eval)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]]\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f489d114170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.34163994, 0.32818028, 0.33017975],\n",
              "       [0.34163994, 0.32818028, 0.33017975],\n",
              "       [0.34163994, 0.32818028, 0.33017975]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpCC3vUyzzFH"
      },
      "source": [
        "# Model with look-alikes and no hog used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JAl-DSUwyKe"
      },
      "source": [
        "x_tra1n, x_t3mp, y_tra1n, y_t3mp = train_test_split(plant_imgs, plant_labels, test_size = .2)\n",
        "x_t3st, x_3val, y_t3st, y_3val = train_test_split(x_t3mp, y_t3mp, test_size = .03)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIAD-pwPwNRe"
      },
      "source": [
        "# build model\n",
        "m0del = keras.models.Sequential()\n",
        "m0del.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(50, 50, 3))) # convolutional networks to make image smaller\n",
        "m0del.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "m0del.add(MaxPooling2D(pool_size=(2,2))) # pool pixels to get largest value\n",
        "m0del.add(Flatten()) # flatten model to prepare for hidden layer\n",
        "m0del.add(Dense(50, activation='relu')) # fully connected, 'hidden' layer\n",
        "'''can add dropout here if model overfits'''\n",
        "m0del.add(Dense(3, activation='softmax')) # prediction layer\n",
        "\n",
        "# show summary of model\n",
        "m0del.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq_y1CXBwkX-"
      },
      "source": [
        "m0del.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(learning_rate=.001), metrics=['accuracy'])\n",
        "m0del.fit(x_tra1n, y_tra1n, epochs=100, validation_data=(x_t3st, y_t3st))\n",
        "\n",
        "t3st_eval = m0del.evaluate(x_t3st, y_t3st, verbose=False)\n",
        "print(\"Test loss, accuracy: %s, %s\" % (t3st_eval[0], t3st_eval[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IY2Z101oz7OV"
      },
      "source": [
        "print(y_3val)\n",
        "m0del.predict(x_3val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGiEPLmrE2RW"
      },
      "source": [
        "# Model using falses (pampas grasses)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnEX2XtmKGk2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e85653f5-1150-46a2-ab36-e554ade38b32"
      },
      "source": [
        "poison_falses = np.concatenate((poison_hog, false_pg_hog))\n",
        "pf_labels = np.concatenate((poison_labels, false_labels))\n",
        "a_train, a_temp, b_train, b_temp = train_test_split(poison_falses, pf_labels, test_size=.2)\n",
        "a_test, a_eval, b_test, b_eval = train_test_split(a_temp, b_temp, test_size=.03)\n",
        "\n",
        "print('atrain:\\t',len(a_train))\n",
        "print('atest:\\t',len(a_test))\n",
        "print('aeval:\\t',len(a_eval))\n",
        "print(b_eval)\n",
        "\n",
        "len(a_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "atrain:\t 313\n",
            "atest:\t 76\n",
            "aeval:\t 3\n",
            "[[0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42849"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDn7cjPeKov_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a10ba1b-e314-4320-d7c2-ca19575b8ce6"
      },
      "source": [
        "fmodel = keras.models.Sequential()\n",
        "fmodel.add(Dense(50, activation='relu', input_shape=(42849,)))\n",
        "fmodel.add(Dense(50, activation='relu'))\n",
        "fmodel.add(Dropout(.1))\n",
        "fmodel.add(Dense(3, activation='softmax'))\n",
        "\n",
        "fmodel.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_45 (Dense)             (None, 50)                2142500   \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 3)                 153       \n",
            "=================================================================\n",
            "Total params: 2,145,203\n",
            "Trainable params: 2,145,203\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe8uzuQxK1wK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6691edfd-f9e3-492d-f925-82c002f4b307"
      },
      "source": [
        "fmodel.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(learning_rate=.001), metrics=['accuracy'])\n",
        "fmodel.fit(a_train, b_train, epochs=100, validation_data=(a_test, b_test))\n",
        "\n",
        "ab_test_eval = model.evaluate(a_test, b_test, verbose=False)\n",
        "print(\"Test loss, accuracy: %s, %s\" % (ab_test_eval[0], ab_test_eval[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 1s 43ms/step - loss: 0.6928 - accuracy: 0.3476 - val_loss: 0.6916 - val_accuracy: 0.3026\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6912 - accuracy: 0.3689 - val_loss: 0.6901 - val_accuracy: 0.3026\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6897 - accuracy: 0.3300 - val_loss: 0.6887 - val_accuracy: 0.3026\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6883 - accuracy: 0.3230 - val_loss: 0.6873 - val_accuracy: 0.3026\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6869 - accuracy: 0.3796 - val_loss: 0.6859 - val_accuracy: 0.3026\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6855 - accuracy: 0.3646 - val_loss: 0.6846 - val_accuracy: 0.3026\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6842 - accuracy: 0.3401 - val_loss: 0.6833 - val_accuracy: 0.3026\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6829 - accuracy: 0.3692 - val_loss: 0.6821 - val_accuracy: 0.3026\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6816 - accuracy: 0.3440 - val_loss: 0.6809 - val_accuracy: 0.3026\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6803 - accuracy: 0.3511 - val_loss: 0.6797 - val_accuracy: 0.3026\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6792 - accuracy: 0.3727 - val_loss: 0.6785 - val_accuracy: 0.3026\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6780 - accuracy: 0.3324 - val_loss: 0.6774 - val_accuracy: 0.3026\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6769 - accuracy: 0.3339 - val_loss: 0.6763 - val_accuracy: 0.3026\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6757 - accuracy: 0.3067 - val_loss: 0.6752 - val_accuracy: 0.3026\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6745 - accuracy: 0.3673 - val_loss: 0.6742 - val_accuracy: 0.3026\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6734 - accuracy: 0.3754 - val_loss: 0.6731 - val_accuracy: 0.3026\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6725 - accuracy: 0.3492 - val_loss: 0.6721 - val_accuracy: 0.3026\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6714 - accuracy: 0.3787 - val_loss: 0.6711 - val_accuracy: 0.3026\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6704 - accuracy: 0.3749 - val_loss: 0.6702 - val_accuracy: 0.3026\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6695 - accuracy: 0.3468 - val_loss: 0.6692 - val_accuracy: 0.3026\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6686 - accuracy: 0.3283 - val_loss: 0.6683 - val_accuracy: 0.3026\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6674 - accuracy: 0.3308 - val_loss: 0.6674 - val_accuracy: 0.3026\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6666 - accuracy: 0.3352 - val_loss: 0.6665 - val_accuracy: 0.3026\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6655 - accuracy: 0.3524 - val_loss: 0.6657 - val_accuracy: 0.3026\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6650 - accuracy: 0.3197 - val_loss: 0.6649 - val_accuracy: 0.3026\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6640 - accuracy: 0.3601 - val_loss: 0.6641 - val_accuracy: 0.3026\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6631 - accuracy: 0.3171 - val_loss: 0.6633 - val_accuracy: 0.3026\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6623 - accuracy: 0.3509 - val_loss: 0.6625 - val_accuracy: 0.3026\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6615 - accuracy: 0.2835 - val_loss: 0.6618 - val_accuracy: 0.3026\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6609 - accuracy: 0.3233 - val_loss: 0.6611 - val_accuracy: 0.3026\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6599 - accuracy: 0.3235 - val_loss: 0.6604 - val_accuracy: 0.3026\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6594 - accuracy: 0.3678 - val_loss: 0.6597 - val_accuracy: 0.3026\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6586 - accuracy: 0.3595 - val_loss: 0.6591 - val_accuracy: 0.3026\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.6582 - accuracy: 0.3150 - val_loss: 0.6584 - val_accuracy: 0.3026\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6574 - accuracy: 0.3683 - val_loss: 0.6578 - val_accuracy: 0.3026\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6566 - accuracy: 0.3693 - val_loss: 0.6572 - val_accuracy: 0.3026\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6560 - accuracy: 0.3514 - val_loss: 0.6566 - val_accuracy: 0.3026\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6549 - accuracy: 0.3936 - val_loss: 0.6561 - val_accuracy: 0.3026\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6546 - accuracy: 0.3565 - val_loss: 0.6555 - val_accuracy: 0.3026\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6547 - accuracy: 0.3113 - val_loss: 0.6549 - val_accuracy: 0.3026\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6535 - accuracy: 0.3466 - val_loss: 0.6544 - val_accuracy: 0.3026\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6528 - accuracy: 0.3724 - val_loss: 0.6539 - val_accuracy: 0.3026\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6528 - accuracy: 0.3384 - val_loss: 0.6534 - val_accuracy: 0.3026\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6525 - accuracy: 0.3324 - val_loss: 0.6530 - val_accuracy: 0.3026\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6514 - accuracy: 0.3601 - val_loss: 0.6525 - val_accuracy: 0.3026\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6506 - accuracy: 0.3344 - val_loss: 0.6521 - val_accuracy: 0.2895\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6500 - accuracy: 0.3977 - val_loss: 0.6517 - val_accuracy: 0.2895\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6495 - accuracy: 0.3834 - val_loss: 0.6512 - val_accuracy: 0.2895\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6493 - accuracy: 0.3365 - val_loss: 0.6508 - val_accuracy: 0.2895\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6492 - accuracy: 0.2851 - val_loss: 0.6504 - val_accuracy: 0.3026\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6485 - accuracy: 0.3116 - val_loss: 0.6500 - val_accuracy: 0.2895\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6484 - accuracy: 0.3505 - val_loss: 0.6497 - val_accuracy: 0.2895\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6478 - accuracy: 0.3940 - val_loss: 0.6493 - val_accuracy: 0.2895\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6472 - accuracy: 0.3562 - val_loss: 0.6490 - val_accuracy: 0.2895\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6480 - accuracy: 0.2828 - val_loss: 0.6486 - val_accuracy: 0.2895\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6469 - accuracy: 0.3469 - val_loss: 0.6483 - val_accuracy: 0.2895\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6469 - accuracy: 0.2760 - val_loss: 0.6480 - val_accuracy: 0.2895\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6459 - accuracy: 0.3047 - val_loss: 0.6477 - val_accuracy: 0.2895\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6462 - accuracy: 0.3525 - val_loss: 0.6474 - val_accuracy: 0.2895\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6455 - accuracy: 0.3669 - val_loss: 0.6471 - val_accuracy: 0.2895\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6454 - accuracy: 0.3280 - val_loss: 0.6468 - val_accuracy: 0.2895\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6442 - accuracy: 0.3552 - val_loss: 0.6466 - val_accuracy: 0.2895\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6439 - accuracy: 0.3590 - val_loss: 0.6463 - val_accuracy: 0.2895\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6441 - accuracy: 0.3806 - val_loss: 0.6461 - val_accuracy: 0.2895\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6431 - accuracy: 0.3841 - val_loss: 0.6459 - val_accuracy: 0.2895\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6428 - accuracy: 0.3648 - val_loss: 0.6456 - val_accuracy: 0.2895\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6433 - accuracy: 0.3541 - val_loss: 0.6454 - val_accuracy: 0.2895\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6429 - accuracy: 0.3545 - val_loss: 0.6452 - val_accuracy: 0.2895\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6423 - accuracy: 0.3668 - val_loss: 0.6450 - val_accuracy: 0.2895\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6431 - accuracy: 0.3529 - val_loss: 0.6448 - val_accuracy: 0.2895\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6429 - accuracy: 0.2819 - val_loss: 0.6446 - val_accuracy: 0.2895\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6419 - accuracy: 0.3097 - val_loss: 0.6444 - val_accuracy: 0.3026\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6424 - accuracy: 0.3095 - val_loss: 0.6442 - val_accuracy: 0.2895\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6417 - accuracy: 0.3461 - val_loss: 0.6441 - val_accuracy: 0.3026\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6412 - accuracy: 0.3625 - val_loss: 0.6439 - val_accuracy: 0.3026\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6414 - accuracy: 0.3308 - val_loss: 0.6438 - val_accuracy: 0.3026\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6404 - accuracy: 0.3759 - val_loss: 0.6436 - val_accuracy: 0.3026\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6408 - accuracy: 0.3600 - val_loss: 0.6435 - val_accuracy: 0.3026\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6399 - accuracy: 0.3483 - val_loss: 0.6434 - val_accuracy: 0.3026\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6402 - accuracy: 0.3691 - val_loss: 0.6432 - val_accuracy: 0.3026\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6395 - accuracy: 0.3512 - val_loss: 0.6431 - val_accuracy: 0.3026\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6398 - accuracy: 0.3550 - val_loss: 0.6430 - val_accuracy: 0.3026\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6394 - accuracy: 0.3621 - val_loss: 0.6429 - val_accuracy: 0.3026\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6399 - accuracy: 0.3339 - val_loss: 0.6428 - val_accuracy: 0.3026\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6397 - accuracy: 0.3491 - val_loss: 0.6426 - val_accuracy: 0.3026\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6399 - accuracy: 0.3362 - val_loss: 0.6425 - val_accuracy: 0.3026\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6384 - accuracy: 0.3044 - val_loss: 0.6425 - val_accuracy: 0.2895\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6395 - accuracy: 0.3196 - val_loss: 0.6423 - val_accuracy: 0.3026\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6387 - accuracy: 0.3473 - val_loss: 0.6422 - val_accuracy: 0.3026\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6385 - accuracy: 0.3455 - val_loss: 0.6422 - val_accuracy: 0.3026\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6392 - accuracy: 0.3166 - val_loss: 0.6421 - val_accuracy: 0.2895\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6383 - accuracy: 0.2936 - val_loss: 0.6420 - val_accuracy: 0.2895\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6385 - accuracy: 0.2722 - val_loss: 0.6419 - val_accuracy: 0.2895\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6383 - accuracy: 0.3268 - val_loss: 0.6419 - val_accuracy: 0.3026\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6388 - accuracy: 0.3339 - val_loss: 0.6418 - val_accuracy: 0.2895\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6379 - accuracy: 0.3410 - val_loss: 0.6417 - val_accuracy: 0.3026\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6385 - accuracy: 0.3178 - val_loss: 0.6417 - val_accuracy: 0.2895\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6386 - accuracy: 0.3293 - val_loss: 0.6416 - val_accuracy: 0.2895\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6384 - accuracy: 0.3647 - val_loss: 0.6416 - val_accuracy: 0.2895\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 25ms/step - loss: 0.6385 - accuracy: 0.3524 - val_loss: 0.6415 - val_accuracy: 0.2895\n",
            "Test loss, accuracy: 0.6376585364341736, 0.40789473056793213\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AtzoH7FLHv1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aca03bce-6f0d-4829-f254-dd232f61e37e"
      },
      "source": [
        "print(b_eval)\n",
        "fmodel.predict(a_eval)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.3102557 , 0.34494147, 0.3448028 ],\n",
              "       [0.3102557 , 0.34494147, 0.3448028 ],\n",
              "       [0.3102557 , 0.34494147, 0.3448028 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19273mNcJU9A"
      },
      "source": [
        "# Model using irises"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI7KYEyJLN_1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26b686f8-d5e6-4d7d-c6c3-f700a5d5ec10"
      },
      "source": [
        "poison_iris = np.concatenate((poison_hog, iris_hog))\n",
        "pi_labels = np.concatenate((poison_labels, iris_labels))\n",
        "i_train, i_temp, j_train, j_temp = train_test_split(poison_iris, pi_labels, test_size=.2)\n",
        "i_test, i_eval, j_test, j_eval = train_test_split(i_temp, j_temp, test_size=.03)\n",
        "\n",
        "print('itrain:\\t',len(i_train))\n",
        "print('itest:\\t',len(i_test))\n",
        "print('ieval:\\t',len(i_eval))\n",
        "print(j_eval)\n",
        "\n",
        "len(i_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "itrain:\t 316\n",
            "itest:\t 77\n",
            "ieval:\t 3\n",
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42849"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30U7c6UnNlb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4be33dd7-9e9f-4e0e-e3fb-ec9e0d3211a2"
      },
      "source": [
        "imodel = keras.models.Sequential()\n",
        "imodel.add(Dense(50, activation='relu', input_shape=(42849,)))\n",
        "imodel.add(Dense(50,activation='relu'))\n",
        "imodel.add(Dropout(.1))\n",
        "imodel.add(Dense(3, activation='softmax'))\n",
        "\n",
        "imodel.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_50 (Dense)             (None, 50)                2142500   \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 3)                 153       \n",
            "=================================================================\n",
            "Total params: 2,145,203\n",
            "Trainable params: 2,145,203\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vvBW-pnRqxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eca2de1e-6a83-47cf-ea34-781ffa0400f7"
      },
      "source": [
        "\n",
        "imodel.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "imodel.fit(i_train, j_train, epochs=100, validation_data=(i_test, j_test))\n",
        "\n",
        "ij_test_eval = model.evaluate(i_test, j_test, verbose=False)\n",
        "print(f'Test loss, accuracty: {ij_test_eval[0]}, {ij_test_eval[1]}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 1s 48ms/step - loss: 0.6928 - accuracy: 0.3922 - val_loss: 0.6917 - val_accuracy: 0.2857\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.6913 - accuracy: 0.3461 - val_loss: 0.6903 - val_accuracy: 0.2857\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6899 - accuracy: 0.3509 - val_loss: 0.6888 - val_accuracy: 0.2857\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6884 - accuracy: 0.3273 - val_loss: 0.6874 - val_accuracy: 0.2857\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6870 - accuracy: 0.3539 - val_loss: 0.6860 - val_accuracy: 0.2857\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6856 - accuracy: 0.3275 - val_loss: 0.6847 - val_accuracy: 0.2857\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6843 - accuracy: 0.3645 - val_loss: 0.6834 - val_accuracy: 0.2857\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6829 - accuracy: 0.3577 - val_loss: 0.6821 - val_accuracy: 0.2857\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6816 - accuracy: 0.3713 - val_loss: 0.6808 - val_accuracy: 0.2857\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6804 - accuracy: 0.3645 - val_loss: 0.6796 - val_accuracy: 0.2857\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6792 - accuracy: 0.3513 - val_loss: 0.6784 - val_accuracy: 0.2857\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.6780 - accuracy: 0.3415 - val_loss: 0.6773 - val_accuracy: 0.2857\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6768 - accuracy: 0.3363 - val_loss: 0.6761 - val_accuracy: 0.2857\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6757 - accuracy: 0.3619 - val_loss: 0.6750 - val_accuracy: 0.2857\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6746 - accuracy: 0.3500 - val_loss: 0.6740 - val_accuracy: 0.2857\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6735 - accuracy: 0.3627 - val_loss: 0.6729 - val_accuracy: 0.2857\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.6725 - accuracy: 0.3287 - val_loss: 0.6719 - val_accuracy: 0.2857\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.6715 - accuracy: 0.3436 - val_loss: 0.6709 - val_accuracy: 0.2857\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6704 - accuracy: 0.3510 - val_loss: 0.6699 - val_accuracy: 0.2857\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6695 - accuracy: 0.3374 - val_loss: 0.6690 - val_accuracy: 0.2857\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6684 - accuracy: 0.3700 - val_loss: 0.6680 - val_accuracy: 0.2857\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6676 - accuracy: 0.3441 - val_loss: 0.6671 - val_accuracy: 0.2857\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6666 - accuracy: 0.3481 - val_loss: 0.6663 - val_accuracy: 0.2857\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6658 - accuracy: 0.3340 - val_loss: 0.6654 - val_accuracy: 0.2857\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6648 - accuracy: 0.3658 - val_loss: 0.6646 - val_accuracy: 0.2857\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6639 - accuracy: 0.3749 - val_loss: 0.6637 - val_accuracy: 0.2857\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6632 - accuracy: 0.3482 - val_loss: 0.6629 - val_accuracy: 0.2857\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6624 - accuracy: 0.3523 - val_loss: 0.6622 - val_accuracy: 0.2857\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6616 - accuracy: 0.3589 - val_loss: 0.6614 - val_accuracy: 0.2857\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.6610 - accuracy: 0.3282 - val_loss: 0.6607 - val_accuracy: 0.2857\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6599 - accuracy: 0.3925 - val_loss: 0.6600 - val_accuracy: 0.2857\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6593 - accuracy: 0.3653 - val_loss: 0.6593 - val_accuracy: 0.2857\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6587 - accuracy: 0.3443 - val_loss: 0.6586 - val_accuracy: 0.2857\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.6581 - accuracy: 0.3437 - val_loss: 0.6579 - val_accuracy: 0.2857\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6574 - accuracy: 0.3245 - val_loss: 0.6572 - val_accuracy: 0.2857\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6567 - accuracy: 0.3484 - val_loss: 0.6566 - val_accuracy: 0.2857\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6560 - accuracy: 0.3639 - val_loss: 0.6560 - val_accuracy: 0.2857\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6552 - accuracy: 0.3669 - val_loss: 0.6554 - val_accuracy: 0.2857\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6548 - accuracy: 0.3466 - val_loss: 0.6548 - val_accuracy: 0.2857\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6541 - accuracy: 0.3579 - val_loss: 0.6543 - val_accuracy: 0.2857\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.6538 - accuracy: 0.3237 - val_loss: 0.6537 - val_accuracy: 0.2857\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6530 - accuracy: 0.3477 - val_loss: 0.6532 - val_accuracy: 0.2857\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6524 - accuracy: 0.3750 - val_loss: 0.6527 - val_accuracy: 0.2857\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6523 - accuracy: 0.3231 - val_loss: 0.6522 - val_accuracy: 0.2857\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.6517 - accuracy: 0.3266 - val_loss: 0.6517 - val_accuracy: 0.2857\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6513 - accuracy: 0.3051 - val_loss: 0.6512 - val_accuracy: 0.2857\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6507 - accuracy: 0.3323 - val_loss: 0.6508 - val_accuracy: 0.2857\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6501 - accuracy: 0.3551 - val_loss: 0.6503 - val_accuracy: 0.2857\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6498 - accuracy: 0.3505 - val_loss: 0.6499 - val_accuracy: 0.2857\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.6488 - accuracy: 0.3779 - val_loss: 0.6495 - val_accuracy: 0.2857\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6487 - accuracy: 0.3520 - val_loss: 0.6491 - val_accuracy: 0.2857\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.6485 - accuracy: 0.3304 - val_loss: 0.6487 - val_accuracy: 0.2857\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6479 - accuracy: 0.3617 - val_loss: 0.6483 - val_accuracy: 0.2857\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6476 - accuracy: 0.3420 - val_loss: 0.6479 - val_accuracy: 0.2857\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.6472 - accuracy: 0.3340 - val_loss: 0.6476 - val_accuracy: 0.2857\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6468 - accuracy: 0.3509 - val_loss: 0.6472 - val_accuracy: 0.2857\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6469 - accuracy: 0.3035 - val_loss: 0.6469 - val_accuracy: 0.2857\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6465 - accuracy: 0.3086 - val_loss: 0.6466 - val_accuracy: 0.2857\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6455 - accuracy: 0.3510 - val_loss: 0.6463 - val_accuracy: 0.2857\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6452 - accuracy: 0.3649 - val_loss: 0.6460 - val_accuracy: 0.2857\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6450 - accuracy: 0.3615 - val_loss: 0.6457 - val_accuracy: 0.2857\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.6447 - accuracy: 0.3592 - val_loss: 0.6454 - val_accuracy: 0.2857\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.6445 - accuracy: 0.3453 - val_loss: 0.6451 - val_accuracy: 0.2857\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6443 - accuracy: 0.3487 - val_loss: 0.6448 - val_accuracy: 0.2857\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.6439 - accuracy: 0.3638 - val_loss: 0.6446 - val_accuracy: 0.2857\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6437 - accuracy: 0.3476 - val_loss: 0.6443 - val_accuracy: 0.2857\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6435 - accuracy: 0.3531 - val_loss: 0.6441 - val_accuracy: 0.2857\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6430 - accuracy: 0.3652 - val_loss: 0.6438 - val_accuracy: 0.2857\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6430 - accuracy: 0.3471 - val_loss: 0.6436 - val_accuracy: 0.2857\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.6429 - accuracy: 0.3244 - val_loss: 0.6434 - val_accuracy: 0.2857\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.6424 - accuracy: 0.3531 - val_loss: 0.6432 - val_accuracy: 0.2857\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6420 - accuracy: 0.3556 - val_loss: 0.6430 - val_accuracy: 0.2857\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6419 - accuracy: 0.3485 - val_loss: 0.6428 - val_accuracy: 0.2857\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6422 - accuracy: 0.3240 - val_loss: 0.6426 - val_accuracy: 0.2857\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6412 - accuracy: 0.3711 - val_loss: 0.6424 - val_accuracy: 0.2857\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6422 - accuracy: 0.2920 - val_loss: 0.6422 - val_accuracy: 0.2857\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6417 - accuracy: 0.3155 - val_loss: 0.6420 - val_accuracy: 0.2857\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6410 - accuracy: 0.3499 - val_loss: 0.6419 - val_accuracy: 0.2857\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6408 - accuracy: 0.3498 - val_loss: 0.6417 - val_accuracy: 0.2857\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6415 - accuracy: 0.2944 - val_loss: 0.6415 - val_accuracy: 0.2857\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.6403 - accuracy: 0.3603 - val_loss: 0.6414 - val_accuracy: 0.2857\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6404 - accuracy: 0.3464 - val_loss: 0.6413 - val_accuracy: 0.2857\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6405 - accuracy: 0.3290 - val_loss: 0.6411 - val_accuracy: 0.2857\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.6397 - accuracy: 0.3744 - val_loss: 0.6410 - val_accuracy: 0.2857\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6401 - accuracy: 0.3465 - val_loss: 0.6409 - val_accuracy: 0.2857\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 26ms/step - loss: 0.6400 - accuracy: 0.3354 - val_loss: 0.6408 - val_accuracy: 0.2857\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6397 - accuracy: 0.3395 - val_loss: 0.6407 - val_accuracy: 0.2857\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.6393 - accuracy: 0.3701 - val_loss: 0.6406 - val_accuracy: 0.2857\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6391 - accuracy: 0.3768 - val_loss: 0.6405 - val_accuracy: 0.2857\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6396 - accuracy: 0.3293 - val_loss: 0.6403 - val_accuracy: 0.2857\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6392 - accuracy: 0.3414 - val_loss: 0.6402 - val_accuracy: 0.2857\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6394 - accuracy: 0.3210 - val_loss: 0.6401 - val_accuracy: 0.2857\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.6386 - accuracy: 0.3647 - val_loss: 0.6401 - val_accuracy: 0.2857\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6389 - accuracy: 0.3473 - val_loss: 0.6400 - val_accuracy: 0.2857\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6382 - accuracy: 0.3708 - val_loss: 0.6399 - val_accuracy: 0.2857\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6381 - accuracy: 0.3728 - val_loss: 0.6398 - val_accuracy: 0.2857\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6385 - accuracy: 0.3429 - val_loss: 0.6397 - val_accuracy: 0.2857\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6378 - accuracy: 0.3852 - val_loss: 0.6397 - val_accuracy: 0.2857\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.6382 - accuracy: 0.3562 - val_loss: 0.6396 - val_accuracy: 0.2857\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.6388 - accuracy: 0.3252 - val_loss: 0.6395 - val_accuracy: 0.2857\n",
            "Test loss, accuracty: 0.6393712759017944, 0.2857142984867096\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXGOanb4RskA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99416b1b-9bc7-4dc0-c453-2616ebeba7cd"
      },
      "source": [
        "\n",
        "print(j_eval)\n",
        "fmodel.predict(i_eval)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 1.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.33505005, 0.34478676, 0.32016316],\n",
              "       [0.33505005, 0.34478676, 0.32016316],\n",
              "       [0.33505005, 0.34478676, 0.32016316]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    }
  ]
}